{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import multiprocessing as mlp\n",
    "import random\n",
    "import pandas as pd\n",
    "import easyaccess as ea\n",
    "import numpy as np\n",
    "import re\n",
    "import psycopg2\n",
    "import subprocess\n",
    "import time\n",
    "from subprocess import Popen, PIPE\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #figure out if the desgw folder exists here... if not, download it from git\n",
    "\n",
    "\n",
    "query = \"\"\"select distinct season from MARCELLE.SNAUTOSCAN union select distinct season from MARCELLE.SNAUTOSCAN_SAVE union select distinct season from MARCELLE.SNCAND union select distinct season from MARCELLE.SNFAKEIMG union select distinct season from MARCELLE.SNFAKEMATCH union select distinct season from MARCELLE.SNFORCE union select distinct season from MARCELLE.SNOBS union select distinct season from MARCELLE.SNOBSINFO union select distinct season from MARCELLE.SNOBS_SAVE union select distinct season from MARCELLE.SNSCAN ;\"\"\" \n",
    "\n",
    "DF=ea.connect('dessci').query_to_pandas(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(queried_list):\n",
    "    \n",
    "    df = pd.DataFrame(columns=['season','exposure', 'nite', 'radeg', 'decdeg']) # Create empty dataframe to which to append query results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = DF['SEASON']\n",
    "used_seasons = []\n",
    "a_list = list(range(1, 100))\n",
    "used_seasons.append(5000)\n",
    "used_seasons.append(6000)\n",
    "\n",
    "for number in a_list:\n",
    "    used_seasons.append(number)\n",
    "\n",
    "for i in seasons:\n",
    "    if i.is_integer():\n",
    "        integer_value = int(i)\n",
    "    else:\n",
    "        integer_value = 0\n",
    "    used_seasons.append(integer_value)\n",
    "\n",
    "    #save the event data along with the season number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = (input(\"Is this a test? [y/n]\"))\n",
    "test = test_check\n",
    "if test == ('y'):\n",
    "#         #des gw testing suite and season number \n",
    "    raise Exception('Sorry! Not done w/ this part of the code yet')\n",
    "if test != ('n'):\n",
    "    raise Exception('Please restart and enter y/n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputted_season = (input(\"Enter desired season. If you have no input in mind, enter 'random':\"))\n",
    "if inputted_season.isdigit():\n",
    "    SEASON = int(inputted_season)\n",
    "elif inputted_season == ('random'):\n",
    "    SEASON = 'random'\n",
    "else:\n",
    "    raise Exception('Please make sure you have inputted a number or the word \"random\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for new data, start with asking for a user input of desired season. then check if season is redundant\n",
    "i = 0\n",
    "while i < 1: \n",
    "\n",
    "        print('Checking if season number is redundant...')\n",
    "        \n",
    "        if SEASON == ('random'):\n",
    "            SEASON = random.randint(100, 10000)\n",
    "            i = 0\n",
    "        \n",
    "        elif int(SEASON) in used_seasons:                         \n",
    "            answer = (input(\"Input matches previously used value. Proceeding with this Season input will overwrite previous files. Would you like to keep this input and overwrite previous files? [y/n]:\"))\n",
    "            answer_input = answer\n",
    "            \n",
    "            if answer_input == ('y'):\n",
    "                answer_input_2 = (input(\"Are you SURE you want to overwrite previous values and continue with this number? [y/n]:\"))\n",
    "                answer_2 = answer_input_2\n",
    "                if answer_2 == ('y'):\n",
    "                    new_season = (input(\"YOU CAn'T OVERWRITE pRevIouS FILeS!!!! Pick a new number.\"))\n",
    "                    new_value = int(new_season)\n",
    "                    SEASON = new_value\n",
    "                    i = 0   \n",
    "                    \n",
    "                else:\n",
    "                    new_season = (input(\"Please enter a new value for SEASON:\"))\n",
    "                    new_value = int(new_season)\n",
    "                    SEASON = new_value\n",
    "                    i = 0        \n",
    "            elif answer_input != ('n'):  \n",
    "                raise Exception('You gotta enter y or n or the code will break for now')\n",
    "            else:\n",
    "                new_input = input(\"Please enter a new value for SEASON:\")\n",
    "                SEASON = new_input\n",
    "                i = 0\n",
    "            \n",
    "        elif SEASON not in used_seasons:\n",
    "            print(\"Input accepted. SEASON = \", SEASON)\n",
    "            i = 1\n",
    "            \n",
    "        else:\n",
    "            raise ERROR(\"Something's gone wrong. Please restart and input a new season number.\")\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_other_stuff = (input(\"Would you like to update any other parameters? If you know something you'd like to update, type it here. Enter 'n' for no. For syntax/a list of possible updates, type 'help'.\"))\n",
    "update = update_other_stuff \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBSUBS_OPTS = None\n",
    "RM_MYTEMP = None\n",
    "JOBSUBS_OPTS_SE = None\n",
    "RESOURCES = None\n",
    "IGNORECALIB = None\n",
    "DESTCACHE = None\n",
    "TWINDOW = None\n",
    "MIN_NITE = None\n",
    "MAX_NITE = None\n",
    "SKIP_INCOMPLETE_SE = None\n",
    "DO_HEADER_CHECK = None\n",
    "\n",
    "TEFF_CUT_g = None\n",
    "TEFF_CUT_i = None\n",
    "TEFF_CUT_r= None\n",
    "TEFF_CUT_Y= None\n",
    "TEFF_CUT_z= None\n",
    "TEFF_CUT_u= None\n",
    "list_parameters = [TEFF_CUT_g, TEFF_CUT_i, TEFF_CUT_r, TEFF_CUT_Y, TEFF_CUT_z, TEFF_CUT_u, JOBSUBS_OPS, RM_MYTEMP, JOBSUBS_OPTS_SE, RESOURCES, IGNORECALIB, DESTCACHE, TWINDOW, MIN_NITE, MAX_NITE, SKIP_INCOMPLETE_SE, DO_HEADER_CHECK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameter(parameter):\n",
    "    new_parameter_input = (input(f\"What would you like to update to?\")) \n",
    "    new_parameter = new_parameter_input\n",
    "    return new_parameter\n",
    "\n",
    "\n",
    "    \n",
    "def ask_restart():\n",
    "    restart_or_no = (input('Would you like to update parameters? [y/n/help]'))\n",
    "    answer_restart = restart_or_no\n",
    "    if restart_or_no == ('y'):\n",
    "        update_more = (input(\"Would you like to update any other parameters? If you know something you'd like to update, type it here. For syntax/a list of possible updates, type 'help'.\"))\n",
    "        update_value = update_more\n",
    "        i = 0\n",
    "    elif restart_or_no == ('n'):\n",
    "        update_value = None\n",
    "        i = 1\n",
    "        \n",
    "    return {'i': i, 'update_value': update_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 1:\n",
    "    \n",
    "    if update == ('help'):\n",
    "        \n",
    "        print(\"RM_MYTEMP, JOBSUBS_OPTS, JOBSUBS_OPTS_SE, RESOURCES, IGNORECALIB, DESTCACHE, TEFF_CUT, TWINDOW, MIN_NITE, MAX_NITE, SKIP_INCOMPLETE_SE, DO_HEADER_CHECK\")\n",
    "        i_new = ask_restart()\n",
    "        update = i_new['update_value']\n",
    "        i = i_new['i']\n",
    "        \n",
    "    elif update == ('RM_MYTEMP'):\n",
    "        RM_MYTEMP = update_parameter(RM_MYTEMP)\n",
    "        new_values_rm = ask_restart()\n",
    "        update = new_values_rm['update_value']\n",
    "        i = new_values_rm['i']\n",
    "        \n",
    "    elif (update == 'JOBSUB_OPTS'):\n",
    "        JOBSUB_OPTS = update_parameter(JOBSUB_OPTS)\n",
    "        new_values_jo = ask_restart()\n",
    "        update = new_values_jo['update_value']\n",
    "        i = new_values_jo['i']\n",
    "        \n",
    "    elif (update == 'JOBSUBS_OPTS_SE'):\n",
    "        JOBSUB_OPTS_SE = update_parameter(JOBSUB_OPTS_SE)\n",
    "        new_values_jos = ask_restart()\n",
    "        update = new_values_jos['update_value']\n",
    "        i = new_values_jos['i']\n",
    "        \n",
    "    elif (update == 'RESOURCES'):\n",
    "        RESOURCES = update_parameter(RESOURCES)\n",
    "        new_values_r = ask_restart()\n",
    "        update = new_values_r['update_value']\n",
    "        i = new_values_r['i']\n",
    "        \n",
    "    elif (update == 'IGNORECALIB'):\n",
    "        IGNORECALIB = update_parameter(IGNORECALIB)\n",
    "        new_values_ic = ask_restart()\n",
    "        update = new_values_ic['update_value']\n",
    "        i = new_values_ic['i']\n",
    "        \n",
    "    elif (update == 'DESTCACHE'):\n",
    "        DESTCACHE = update_parameter(DESTCACHE)\n",
    "        new_values_dc = ask_restart()\n",
    "        update = new_values_dc['update_value']\n",
    "        i = new_values_dc['i']\n",
    "        \n",
    "    elif (update == 'TEFF_CUT_g'):\n",
    "        TEFF_CUT_g = update_parameter(TEFF_CUT_g)\n",
    "        new_values_tcg = ask_restart()\n",
    "        update = new_values_tcg['update_value']\n",
    "        i = new_values_tcg['i']\n",
    "        \n",
    "    elif (update == 'TEFF_CUT_i'):\n",
    "        TEFF_CUT_i = update_parameter(TEFF_CUT_i)\n",
    "        new_values_tci = ask_restart()\n",
    "        update = new_values_tci['update_value']\n",
    "        i = new_values_tci['i']\n",
    "\n",
    "    elif (update == 'TEFF_CUT_r'):\n",
    "        TEFF_CUT_r = update_parameter(TEFF_CUT_r)\n",
    "        new_values_tcr = ask_restart()\n",
    "        update = new_values_tcr['update_value']\n",
    "        i = new_values_tcr['i']\n",
    "\n",
    "    elif (update == 'TEFF_CUT_Y'):\n",
    "        TEFF_CUT_Y = update_parameter(TEFF_CUT_Y)\n",
    "        new_values_tcy = ask_restart()\n",
    "        update = new_values_tcy['update_value']\n",
    "        i = new_values_tcy['i']\n",
    "\n",
    "    elif (update == 'TEFF_CUT_z'):\n",
    "        TEFF_CUT_z = update_parameter(TEFF_CUT_z)\n",
    "        new_values_tcz = ask_restart()\n",
    "        update = new_values_tcz['update_value']\n",
    "        i = new_values_tcz['i']\n",
    "\n",
    "    elif (update == 'TEFF_CUT_u'):\n",
    "        TEFF_CUT_u = update_parameter(TEFF_CUT_u)\n",
    "        new_values_tcu = ask_restart()\n",
    "        update = new_values_tcu['update_value']\n",
    "        i = new_values_tcu['i']\n",
    "\n",
    "    elif (update == 'TWINDOW'):\n",
    "        TWINDOW = update_parameter(TWINDOW)\n",
    "        new_values_tw = ask_restart()\n",
    "        update = new_values_tw['update_value']\n",
    "        i = new_values_tw['i']\n",
    "        \n",
    "    elif (update == 'MIN_NITE'):\n",
    "        MIN_NITE = update_parameter(MIN_NITE)\n",
    "        new_values_min_n = ask_restart()\n",
    "        update = new_values_min_n['update_value']\n",
    "        i = new_values_min_n['i']\n",
    "        \n",
    "    elif (update == 'MAX_NITE'):\n",
    "        MAX_NITE = update_parameter(MAX_NITE)\n",
    "        new_values_max_n = ask_restart()\n",
    "        update = new_values_max_n['update_value']\n",
    "        i = new_values_max_n['i']\n",
    "        \n",
    "    elif (update == 'SKIP_INCOMPLETE_SE'):\n",
    "        SKIP_INCOMPLETE_SE = update_parameter(SKIP_INCOMPLETE_SE)\n",
    "        new_values_skip = ask_restart()\n",
    "        update = new_values_skip['update_value']\n",
    "        i = new_values_skip['i']\n",
    "        \n",
    "    elif (update == 'DO_HEADER_CHECK'):\n",
    "        DO_HEADER_CHECK= update_parameter(DO_HEADER_CHECK)\n",
    "        new_values_header = ask_restart()\n",
    "        update = new_values_header['update_value']\n",
    "        i = new_values_header['i']\n",
    "        \n",
    "    elif update == ('n'):\n",
    "        i=1\n",
    "        \n",
    "    else:\n",
    "        print('Error. Please enter a value.')\n",
    "        new_values_error = ask_restart()\n",
    "        update = new_values_error['update_value']\n",
    "        i = new_values_error['i']\n",
    "        i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read it in as a string and then edit the python string to edit the dagmaker. then get exposure numbers by asking to input an exposures.list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'gw_workflow/dagmaker_test.rc'\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    cnt = 1\n",
    "    while line:\n",
    "         print(\"Line {}: {}\".format(cnt, line.strip()))\n",
    "         line = fp.readline()\n",
    "         cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'gw_workflow/dagmaker_test.rc'\n",
    "\n",
    "with open(filepath, 'r') as file:\n",
    "    # read a list of lines into data\n",
    "    data = file.readlines()\n",
    "\n",
    "print (data[18])\n",
    "data[18]=f'SEASON={SEASON}\\n'\n",
    "print (data[18])\n",
    "\n",
    "print(list_parameters)\n",
    "if  RM_MYTEMP != (None):\n",
    "    data[23]=f'RM_MYTEMP={RM_MYTEMP}\\n'\n",
    "if  JOBSUBS_OPTS != (None):\n",
    "    data[25]=f'JOBSUB_OPTS={JOBSUB_OPTS}\\n'\n",
    "if  JOBSUBS_OPTS_SE != (None):\n",
    "    data[26]=f'JOBSUB_OPTS_SE={JOBSUB_OPTS_SE}\\n'\n",
    "if  RESOURCES != (None):\n",
    "    data[28]=f'RESOURCES={RESOURCES}\\n'\n",
    "if  IGNORECALIB != (None):\n",
    "    data[29]=f'IGNORECALIB={IGNORECALIB}\\n'\n",
    "if  DESTCACHE != (None):\n",
    "    data[30]=f'DESTCACHE={DESTCACHE}\\n'\n",
    "if  TWINDOW != (None):\n",
    "    data[45]=f'TWINDOW={TWINDOW}\\n'\n",
    "if  SKIP_INCOMPLETE_SE != (None):\n",
    "    data[57]=f'SKIP_INCOMPLETE_SE={SKIP_INCOMPLETE_SE}\\n'\n",
    "if  DO_HEADER_CHECK != (None):\n",
    "    data[60]=f'DO_HEADER_CHECK={DO_HEADER_CHECK}\\n'\n",
    "    \n",
    "if  TEFF_CUT_g != (None):\n",
    "    data[39]=f'TEFF_CUT_g={TEFF_CUT_g}\\n'\n",
    "if  TEFF_CUT_i != (None):\n",
    "    data[40]=f'TEFF_CUT_i={TEFF_CUT_i}\\n'\n",
    "if  TEFF_CUT_r != (None):\n",
    "    data[41]=f'TEFF_CUT_r={TEFF_CUT_r}\\n'\n",
    "if  TEFF_CUT_Y != (None):\n",
    "    data[42]=f'TEFF_CUT_Y={TEFF_CUT_Y}\\n'\n",
    "if  TEFF_CUT_z != (None):\n",
    "    data[43]=f'TEFF_CUT_z={TEFF_CUT_z}\\n'\n",
    "if  TEFF_CUT_u != (None):\n",
    "    data[44]=f'TEFF_CUT_u={TEFF_CUT_u}\\n'\n",
    "\n",
    "with open(filepath, 'w') as file:\n",
    "     file.writelines( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--exp_list', type=str)\n",
    "# parser.add_argument('--coadd', default=False)\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXPlist(explist):\n",
    "    \n",
    "    e = open(explist,'r')\n",
    "    el = e.readlines()\n",
    "    elist = [exp.strip() for exp in el]\n",
    "    e.close()\n",
    "\n",
    "    return elist\n",
    "\n",
    "def getCoadd(eList):\n",
    "    \n",
    "    df = pd.DataFrame(columns=['exposure', 'nite', 'radeg', 'decdeg']) # Create empty dataframe to which to append query results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in eList:\n",
    "        \n",
    "        query_exp = \"\"\"SELECT id as EXPOSURE,\n",
    "        TO_CHAR(date - '12 hours'::INTERVAL, 'YYYYMMDD') AS NITE,\n",
    "        ra AS RADEG,\n",
    "        declination AS DECDEG,\n",
    "        filter as BAND\n",
    "        FROM exposure.exposure\n",
    "        WHERE id =\"\"\"+exp+\"\"\" ORDER BY id\"\"\" \n",
    "\n",
    "        exposure_data = ea.connect('dessci').query_to_pandas(query_exp) #,index_col =\"exposure\")\n",
    "        \n",
    "        df = pd.concat([df,exposure_data]) # Add exposure_data dataframe to overhead dataframe\n",
    "        \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    df = df.set_index('exposure', drop = True)   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " coadd_explist = [] # List for lists of coadd sets\n",
    "    temp_eList = eList[:] # A copy of the list of exposures to be slowly dismant\n",
    "led as coadd sets are found\n",
    "    temp_eList = [int(e) for e in temp_eList]\n",
    "    \n",
    "    for exposure in temp_eList:\n",
    "        exp_ra = df.loc[int(exposure)]['radeg']\n",
    "        exp_dec = df.loc[int(exposure)]['decdeg']\n",
    "        exp_nite = df.loc[int(exposure)]['nite']\n",
    "        exp_band = df.loc[int(exposure)]['band']\n",
    "        \n",
    "        # Winnow df until we just have one that has coadds for given exp\n",
    "        stage1_df = df[df['radeg'] == exp_ra]\n",
    "        stage2_df = stage1_df[stage1_df['decdeg'] == exp_dec]\n",
    "        stage3_df = stage2_df[stage2_df['nite'] == exp_nite]\n",
    "        stage4_df = stage3_df[stage3_df['band'] == exp_band]\n",
    "        \n",
    "        coadds = stage3_df.index.values.tolist() # Select coadd exposures as a list\n",
    "        coadd_explist.append(coadds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coadd in coadds:\n",
    "            temp_eList.remove(coadd)\n",
    "    \n",
    "    coadd_str_list = []\n",
    "    for coadd_set in coadd_explist:\n",
    "        coadd_str = ''\n",
    "        for exp in coadd_set:\n",
    "            if exp == coadd_set[-1]:\n",
    "                coadd_str += str(exp)\n",
    "            else:\n",
    "                coadd_str += str(exp) + ' '\n",
    "        coadd_str_list.append(coadd_str)\n",
    "\n",
    "\n",
    "    return coadd_str_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposures = EXPlist(args.exp_list)\n",
    "if args.coadd:\n",
    "    exposures = getCoadd(exposures)\n",
    "    \n",
    "## Get expsure groups\n",
    "len_exps = len(exposures)\n",
    "if args.coadd:\n",
    "    print(\"The number of coadd sets is \" + str(len_exps) + \".\")\n",
    "else:\n",
    "    print(\"The number of exposures is \"+ str(len_exps) + \".\")\n",
    "last_set_len = len_exps % 5 # For submissions of 4 DAGmaker run at a time, the size of the last set of DAGmaker runs\n",
    "num_full_sets = len_exps // 5 # Number of DAGmaker sets of 4 runs\n",
    "if last_set_len > 0:\n",
    "    number_o_sets = num_full_sets + 1\n",
    "    print(\"The number of threaded DAGmaker runs will be \"+ str(number_o_sets)+\": \"+str(num_full_sets) + \" sets of 5 DAGmaker runs and 1 set of \"+ str(last_set_len) + \" DAGmaker run(s).\")\n",
    "else:\n",
    "    number_o_sets = num_full_sets\n",
    "    print(\"The number of threaded DAGmaker runs will be \"+ str(number_o_sets)+\": \"+str(num_full_sets) + \" sets of 5 DAGmaker runs.\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run DAGMaker\n",
    "start_index = 0\n",
    "for i in range(num_full_sets):\n",
    "\n",
    "    exp1_index = start_index\n",
    "    exp2_index = start_index + 1\n",
    "    exp3_index = start_index + 2\n",
    "    exp4_index = start_index + 3\n",
    "    exp5_index = start_index + 4\n",
    "\n",
    "    start_index += 5\n",
    "    \n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp1_index]]\n",
    "    process1 = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(\"Running \" + cmd[0])\n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp2_index]]\n",
    "    process2 = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(\"Running \" + cmd[0])\n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp3_index]]\n",
    "    \n",
    " process3 = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=T\n",
    "rue, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(\"Running \" + cmd[0])\n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp4_index]]\n",
    "    process4 = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(\"Running \" + cmd[0])\n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp5_index]]\n",
    "    process5 = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(\"Running \" + cmd[0])\n",
    "\n",
    "    jobsub_info = []\n",
    "    rel_exps = []\n",
    "    for exposure, process in zip(exposures[exp1_index : exp5_index +1],[process1, process2, process3, process4, process5]):\n",
    "        stdout, stderr = process.communicate()\n",
    "        f = open('dagmaker_'+exposure+'.out', 'w')\n",
    "        f.write(stdout)\n",
    "        if stderr != None:\n",
    "            f.write(stderr)\n",
    "       f.close() \n",
    "        jsub = subprocess.check_output(['tail', '-3', 'dagmaker_'+exposure+'.out'])\n",
    "        jsub = jsub.split(b'\\n')\n",
    "    \n",
    "        try:\n",
    "\n",
    "            if jsub[0].decode('ascii') == 'NO TEMPLATE IMAGES, DIFFIMG WILL FAIL':\n",
    "                print(jsub[0].decode('ascii'))\n",
    "                continue\n",
    "            else:\n",
    "                print('Jobsub command: ' + jsub[-2].decode('ascii'))\n",
    "                jobsub_info.append(jsub[-2].decode('ascii'))\n",
    "                rel_exps.append(exposure)\n",
    "\n",
    "        except(UnicodeDecodeError, AttributeError):\n",
    "\n",
    "            if jsub[0] == 'NO TEMPLATE IMAGES, DIFFIMG WILL FAIL':\n",
    ":\n",
    "           else:\n",
    "                print('Jobsub command: ' + jsub[-2])\n",
    "                jobsub_info.append(jsub[-2])\n",
    "                rel_exps.append(exposure)\n",
    "        \n",
    "    for jobsub_datum in jobsub_info:\n",
    "        if jobsub_datum.split()[0] != 'jobsub_submit_dag':\n",
    "            f = open('Problematic_DAGmaker_Outputs.txt', 'a+')\n",
    "            f.write(str(exposure) + '\\n')\n",
    "            f.close()\n",
    "        else:\n",
    "            cmd = [jobsub_datum]\n",
    "            process = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "            stdout, stderr = process.communicate()\n",
    "            exposure = rel_exps[jobsub_info.index(jobsub_datum)]\n",
    "            f = open('jobsub_'+exposure+'.out', 'w')\n",
    "            f.write(stdout)\n",
    "if stderr != None:\n",
    "                f.write(stderr)\n",
    "                print(\"Something went wrong with submitting the job for \" + exposure + \".\")\n",
    "            f.close()\n",
    "\n",
    "exp_ = []\n",
    "proc_ = []\n",
    "jobsub_info = []\n",
    "rel_exps = []\n",
    "for i in range(last_set_len):\n",
    "    exp_index = -1 - i \n",
    "    cmd = ['./DAGMaker.sh ' + exposures[exp_index]]\n",
    "    process = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print('Running ' + cmd[0])\n",
    "    \n",
    "    exp_.append(exposures[exp_index])\n",
    "    proc_.append(process)\n",
    "    \n",
    "for exposure, process in zip(exp_,proc_):\n",
    "    stdout, stderr = process.communicate()\n",
    " f = open('dagmaker_'+exposure+'.out', 'w')\n",
    "    f.write(stdout)\n",
    "    if stderr != None:\n",
    "        f.write(stderr)\n",
    "    f.close()\n",
    "    jsub = subprocess.check_output(['tail', '-3', 'dagmaker_'+exposure+'.out'])\n",
    "    jsub = jsub.split(b'\\n')\n",
    "    \n",
    "    try:\n",
    "\n",
    "        if jsub[0].decode('ascii') == 'NO TEMPLATE IMAGES, DIFFIMG WILL FAIL':\n",
    "            print(jsub[0].decode('ascii'))\n",
    "            continue\n",
    "        else:\n",
    "            print('Jobsub command: ' + jsub[-2].decode('ascii'))\n",
    "            jobsub_info.append(jsub[-2].decode('ascii'))\n",
    "            rel_exps.append(exposure)\n",
    "            \n",
    "    except(UnicodeDecodeError, AttributeError):\n",
    "        \n",
    "        if jsub[0] == 'NO TEMPLATE IMAGES, DIFFIMG WILL FAIL':\n",
    "                       print(jsub[0])\n",
    "            continue\n",
    "        else:\n",
    "            print('Jobsub command: ' + jsub[-2])\n",
    "            jobsub_info.append(jsub[-2])\n",
    "            rel_exps.append(exposure)\n",
    "    \n",
    "for jobsub_datum in jobsub_info:\n",
    "    if jobsub_datum.split()[0] != 'jobsub_submit_dag':\n",
    "        f = open('Problematic_DAGmaker_Outputs.txt', 'a+')\n",
    "        f.write(str(exposure) + '\\n')\n",
    "        f.close()\n",
    "    else:\n",
    "        cmd = [jobsub_datum]\n",
    "        process = subprocess.Popen(cmd, bufsize=1, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        stdout, stderr = process.communicate()\n",
    "        exposure = rel_exps[jobsub_info.index(jobsub_datum)]\n",
    "        \n",
    "         f = open('jobsub_'+exposure+'.out', 'w')\n",
    "        f.write(stdout)\n",
    "        if stderr != None:\n",
    "            f.write(stderr)\n",
    "            print(\"Something went wrong with submitting the job for \" + exposure + \".\")\n",
    "        f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
